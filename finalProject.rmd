---
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'index.html')) })
title: "Stat 410 Aidan's Movies"
author: "Aidan Gerber"
date: "April 29th, 2022"
output:
  prettydoc::html_pretty:
    toc: yes
    toc_depth: 3
    theme: cayman
    highlight: tango
    df_print: paged
    includes:
      in_header: header.html
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
    includes:
      in_header: header.html
header-includes: \usepackage{setspace}
---
\doublespacing
```{r setup, include=FALSE}
options(scipen=999)
options(digits = 2)
# for PDF full
# knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, dev = 'png')
# SHOW_BACK_TO_TOP=FALSE
# for PDF no code
# knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, dev = 'png', results = 'hide')
# SHOW_BACK_TO_TOP=FALSE
# for html with svg
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, dev = 'svglite', out.width="100%")
SHOW_BACK_TO_TOP=TRUE
```

```{r imports, echo=FALSE, cols.min.print=3}
library(tidyverse)
library(zoo)
library(kit)
library(ggrepel)
library(papeR)
movies <- read_csv('movie.csv')
credits <- read_csv('credit.csv')
# summary(credits)
```

```{r conditional_block0, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat("# [Aidan's Movies](https://www.tradethisandthat.com/movies/)
# [Source Code](https://github.com/AidanG1/stat410)")
```

# Project statement
```{r conditional_block1, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```


#### What is the purpose of your analysis? What effect are you investigating? Why?
The purpose of my analysis is to determine what movies I will enjoy the most. I will do this by creating a model with the response variable of how much I liked a movie out of 100 and predicting it with data on various movie reviews, genres, cast and crew, and more. I am doing this so that I can figure out which movies I will want to watch because I can be confident that I will enjoy them.

# Data description
```{r conditional_block2, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### How were the data collected? How do these data help you answer the relevant research questions?
The data was collected over time by me. A partial dataset in json form is available on my website here: https://www.tradethisandthat.com/movies/api/all_movies/ and a full version is available on the project website: https://stat.aidang.me/continuous_movies.csv. In the references there is python code I wrote to turn the mySQL database into a csv using Django.
Data from TMDB was collected using their API. Data from IMDB was collected by web scraping their page for awards and their page for rating distributions. Much of the data is gotten with python code that I run on movie addition with Django. My rating and metacritic ratings are collected by me.

# Exploratory data analysis 
```{r conditional_block3, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### What are the basic features of the data? What are the variables? How are the variables related? Are there any unusual patterns?

```{r movies_print, cols.min.print=3}
movies_to_print = movies %>% select(name, my_rating, imdb_rating, metacritic_rating, tmdb_rating, imdb_count, tmdb_count, release_date, revenue, budget, award_count, franchise_name, mpaa_name, genres_names, production_company_names)
movies_to_print 
```

```{r continuous_movies_no_na, echo=FALSE, results=FALSE}
continuous_movies_no_na = movies %>% select(my_rating, imdb_rating, tmdb_rating, tmdb_count, metacritic_rating, budget, revenue, award_count, imdb_count, imdb_arithmetic_mean, imdb_median, imdb_top_1000_rating, imdb_top_1000_count, imdb_us_rating, imdb_us_count, imdb_not_us_rating, imdb_not_us_count) %>% drop_na() # a version of the main dataset where rows with NA metacritic ratings are dropped. Metacritic ratings are the only ones that have NA values since some movies are not reviewed by critics on that site.
# continuous_movies_no_na %>% cor()
```

```{r continuous_movies}
create_continuous_movies = function() {
  imdb_mlr = lm(metacritic_rating ~ imdb_rating + award_count + imdb_top_1000_rating, data=continuous_movies_no_na) # creating a basic MLR to interpolate metacritic ratings from imdb ratings
  
  batch_credit_filter = function(movie_ids, person_id_param) {
    # function to create dummy variables of whether a person with a specific id appears in a movie
    results = c()
    for (i in 1:length(movie_ids)) {
      creds = credits %>% filter(movie_id==movie_ids[i])
      results = append(results, ifelse(person_id_param %in% creds$person_id, 1, 0))
    }
    results
  }
  
  continuous_movies = movies %>% # main dplyr code to create the tbl
    arrange(imdb_rating) %>% # since Metacritic ratings have the highest correlation to IMDB ratings
    select(uuid,name,my_rating, imdb_rating, tmdb_rating, tmdb_count, metacritic_rating, budget, revenue, runtime, award_count, imdb_count, imdb_arithmetic_mean, imdb_median, imdb_top_1000_rating, imdb_top_1000_count, imdb_us_rating, imdb_us_count, imdb_not_us_rating, imdb_not_us_count,genres_names,mpaa_name,imdb_rating_percentile,tmdb_rating_percentile,metacritic_rating_percentile) %>% # selecting useful continuous columns
    mutate(metacritic_rating = ifelse(is.na(metacritic_rating), predict(imdb_mlr,data.frame(imdb_rating=imdb_rating, award_count=award_count,imdb_top_1000_rating=imdb_top_1000_rating)), metacritic_rating)) %>% mutate( # interpolating NA metacritic values
      is_action = ifelse(grepl('Action',genres_names),1,0), # creating dummy variables for different genres
      is_comedy = ifelse(grepl('Comedy',genres_names),1,0),
      is_adventure = ifelse(grepl('Adventure',genres_names),1,0),
      is_animation = ifelse(grepl('Animation',genres_names),1,0),
      is_family = ifelse(grepl('Family',genres_names),1,0),
      is_drama = ifelse(grepl('Drama',genres_names),1,0),
      is_scifi = ifelse(grepl('Science Fiction',genres_names),1,0),
      is_thriller = ifelse(grepl('Thriller',genres_names),1,0),
      is_rated_g = ifelse(mpaa_name=='G',1,0),
      is_rated_pg = ifelse(mpaa_name=='PG',1,0),
      is_rated_pg13 = ifelse(mpaa_name=='PG-13',1,0),
      is_rated_r = ifelse(mpaa_name=='R',1,0),
      is_rated_nr = ifelse(mpaa_name=='NR',1,0),
      is_brad_pitt = batch_credit_filter(uuid,'Laq4vXpGTZpfFFqDcHs5KV'), # creating dummy variables for crew members to test significance
      is_stan_lee = batch_credit_filter(uuid,'QzvrSM5wqckocFLj3AEZaV'),
      is_christopher_nolan = batch_credit_filter(uuid,'keZ3UQoTZ4XZKb79VUXDgG'),
      is_spielberg = batch_credit_filter(uuid,'naF68ZLuf7v6upwViuNVUm'),
      is_harrison_ford = batch_credit_filter(uuid,'GTw4tYdeQmWQ6YdgAa3hGu'),
      is_matt_damon = batch_credit_filter(uuid,'czP9E4RMt6u9sfTTML9eMR'),
      is_wes_anderson = batch_credit_filter(uuid,'JVxsaqF8Rxzy3CVxzvQWnd'),
      is_tom_cruise = batch_credit_filter(uuid,'e4Eiprq53YfhZvwmc8SrLr'),
      is_john_williams = batch_credit_filter(uuid,'DyCbZvFwBgugBpjDaqx8kk'),
      is_rdj = batch_credit_filter(uuid,'Bpb5BiRdou7xQHjbU7GUDv'),
      is_quentin_tarantino = batch_credit_filter(uuid,'QLKZWkzmAovVDJXZN8eu3v'),
      is_tom_hanks = batch_credit_filter(uuid,'7tqrqC9rgLHtXckENws9Fy'),
      is_george_lucas = batch_credit_filter(uuid,'DRdnxAsNAZAp7HYsspMMtz'),
      is_leonardo_dicaprio = batch_credit_filter(uuid,'FuCDtnxehhqRrKqh9qC7Dj'),
      is_the_rock = batch_credit_filter(uuid,'VbfEpXpRyzNfjTppSLU9ei'),
      is_stanley_kubrick = batch_credit_filter(uuid,'PfnG2E5kKDAM2PrrUdW9jk'),
      is_john_hughes = batch_credit_filter(uuid,'CkytgUXum2syFtLkgy9dyi'),
      is_jim_carrey = batch_credit_filter(uuid,'T2K6TBzwq2qavcVFeGL8Rc'),
      is_wally_pfister = batch_credit_filter(uuid,'L8jtAQbm3ynBna4857d5j2'),
      is_henry_fonda = batch_credit_filter(uuid,'K5qeaJKmMQen8dMEqY75F4'),
      is_morgan_freeman = batch_credit_filter(uuid,'FHCFi8DwCzoJbCRC34DMRj'),
      is_bong_joon_ho = batch_credit_filter(uuid,'VhJUKLUtNBFJsHcSTiAyMy'),
      is_dustin_hoffman = batch_credit_filter(uuid,'gc7HESshGq5Lh7gD2MH6wR'),
      is_arnold_schwarz = batch_credit_filter(uuid,'JYP3ANQFwkmsQYPGwj77gk'),
      is_jack_nicholson = batch_credit_filter(uuid,'VxqAcnJqT6d7vjcHcpXQoL'),
      is_aamir_khan = batch_credit_filter(uuid,'jWk22meEpdCAhTdpKCfBxg'),
      is_sean_connery = batch_credit_filter(uuid,'57UUtEPqsvkpCSmeGPraq8'),
      is_brad_bird = batch_credit_filter(uuid,'AbANa443DEn6zfpidFA73z'),
      is_natalie_portman = batch_credit_filter(uuid,'JSN7GommYrTooGeh5WzvPg'),
      is_robin_williams = batch_credit_filter(uuid,'C56iyMS2VJXc6gnW3ezcDC'),
      is_sandra_bullock = batch_credit_filter(uuid,'efknfaN8AeojtnMGCfzVR8'),
      is_bill_murray = batch_credit_filter(uuid,'aDeM2LwCunLFnKR4YaziPa'),
    ) %>% select(-genres_names,-uuid,-mpaa_name)
  continuous_movies
}
USE_CACHED = TRUE
if (USE_CACHED) {
  continuous_movies = read_csv('continuous_movies.csv')
} else {
  continuous_movies = create_continuous_movies()
  write_csv(continuous_movies, 'continuous_movies.csv')
}
cor_matrix = continuous_movies %>% select(-name) %>% cor()# creating correlation matrix
cor_matrix[1,]
```

None of the variables are too highly related to my rating. The highest correlations are to imdb_rating, tmdb_rating. The other variables above 0.6 correlation are variables that are highly correlated with imdb_rating like imdb_arithmetic_mean, imdb_us_rating, imdb_top_1000_rating, and imdb_not_us_rating. Ratings like imdb_rating, imdb_arithmetic_mean, imdb_us_rating, imdb_not_us_rating, and imdb_top_1000_rating are highly correlated. Moreover, imdb_ratings and tmdb_rating are also correlated (r=`r cor(continuous_movies$imdb_rating, continuous_movies$tmdb_rating)`). Metacritic rating and imdb_median have weaker correlations, r=`r cor(continuous_movies$imdb_rating, continuous_movies$metacritic_rating)` and r=`r cor(continuous_movies$imdb_rating, continuous_movies$imdb_median)`, respectively. A similar story holds true for the count variables imdb_count, imdb_us_count, and imdb_not_us_count. The correlation between log(imdb_count) and log(tmdb_count) is even `r cor(log(continuous_movies$imdb_count), log(continuous_movies$tmdb_count))`.
Something important to note is that most variables in the dataset make sense linearly such as my_rating and imdb_rating. Since my_rating is on a 0 to 100 scale, other variables within a specific range work best if they are not transformed such as IMDB rating between 0 to 10, TMDB rating between 0 to 10, or Metacritic rating between 0 and 100. 
To create the main dataset for analysis the first thing I did was deciding to interpolate null values rather than removing them The only category with null values was Metacritic rating since some movies are not on Metacritic. To interpolate Metacritic ratings, I created a basic MLR to predict them from movie characteristics that are not related to me or my ratings.
The next step was to make dummy variables for MPAA ratings. The most common MPAA ratings for movies that I have seen are:
`r sort(table(movies$mpaa_name), decreasing = TRUE)[1:5]`
After that, I wrote a function to check if a person of a specific id appeared in a movie and return 1 or 0. This combined the separate credits and movies tables. Credits are 1-to-1 related with both movies and people so I checked those columns.
Finally, it was time to use dplyr to get the dataset. I began by arranging by IMDB rating since Metacritic ratings are most related to IMDB ratings. Then, I selected the desired columns from the larger dataset. After that, I created dummy variables for both genres and crew. I chose every genre that I have seen more than 100 movies from. 

* Comedy(`r sum(continuous_movies$is_comedy)`)
* Adventure(`r sum(continuous_movies$is_adventure)`)
* Action(`r sum(continuous_movies$is_action)`)
* Drama(`r sum(continuous_movies$is_drama)`)
* Family(`r sum(continuous_movies$is_family)`)
* Science Fiction(`r sum(continuous_movies$is_scifi)`)
* Animation(`r sum(continuous_movies$is_animation)`)
* Thriller(`r sum(continuous_movies$is_thriller)`)

Choosing cast and crew members was more difficult. I selected people that I thought had the ability to make movies more than the sum of their parts. I decided to choose many more people than I expected to significant and have them whittled down through AIC, BIC, and other selection methods.
An extra step was creating a caching method since creating continuous_movies takes a few minutes each time. For just the people, it performs `r 32*length(credits$person_id)` calculations.
Looking at the correlation matrix of my rating to all the variables in the final dataset, I noticed that imdb_rating is most significant. Barely behind are tmdb_rating, imdb_arithmetic_mean, imdb_top_1000_rating, imdb_us_rating, imdb_not_us_rating, imdb_rating_percentile, and tmdb_rating_percentile. None of these are surprising and each of them are correlated with each other. There were also reasonably strong correlations between my_rating and imdb_count with less strong ones to award_count, runtime, and revenue. In terms of genres, the highest positive correlation was to drama with large negative correlations to comedy and family. For MPAA ratings, r has a positive correlation and pg13 has a negative correlation. For people, the highest positive correlations were to John Williams, Wally Pfister, Christopher Nolan, Harrison Ford, George Lucas, and Matt Damon.

```{r pairs, echo=FALSE}
high_cor_cm = continuous_movies %>% select(my_rating,imdb_rating,tmdb_rating,imdb_count,metacritic_rating,award_count)
pairs(high_cor_cm) # graphing pairs of specific values
```

# Data analysis
```{r conditional_block4, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### What is the statistical model (or models) that you are using? Why is this an appropriate model to use? Do the model diagnostics contradict the model assumptions? How do you interpret the results from the statistical analysis in the context of your research question?
I tried fitting many different models including SLRs, MLRs, polynomials, montone transformations, ridge, lasso, and GAMs.

## SLR
```{r conditional_block5_1, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r slr}
# begin with some simple models
fit_slr_imdb = lm(my_rating~imdb_rating, data=continuous_movies)
prettify(summary(fit_slr_imdb))
fit_slr_metacritic = lm(my_rating~metacritic_rating, data=continuous_movies)
prettify(summary(fit_slr_metacritic))
fit_slr_tmdb = lm(my_rating~tmdb_rating, data=continuous_movies)
prettify(summary(fit_slr_tmdb))
fit_slr_award = lm(my_rating~imdb_top_1000_count, data=continuous_movies)
prettify(summary(fit_slr_award))
```

```{r slr_plot, echo=FALSE}
plot(continuous_movies$my_rating, fit_slr_imdb$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="SLR My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_slr_metacritic$fitted.values,col="aquamarine3")
points(continuous_movies$my_rating,fit_slr_tmdb$fitted.values,col="firebrick4")
points(continuous_movies$my_rating,fit_slr_award$fitted.values,col="navajowhite")
legend(x = "topleft", title="Models", bg="transparent",
       legend=c("IMDB", "TMDB",'Metacritic','IMDB Top 1000 Count'),
       fill = c("orchid","aquamarine3",'firebrick4','navajowhite'))
abline(0,1)
```
Each of these SLRs have substantial flaws. IMDB ratings are most predictive with an adjusted r squared of `r summary(fit_slr_imdb)$adj.r.squared`, higher than the other models. Each of the models have relatively low betas. This is because RSS highly penalizes particularly far values so it places values toward the center of the range. This is especially apparent for Metacritic which has a beta hat of `r as.numeric(coef(fit_slr_metacritic)[2])`. This means that the total range of predictions is `r min(continuous_movies$metacritic_rating)*as.numeric(coef(fit_slr_metacritic)[2]) + as.numeric(coef(fit_slr_metacritic)[1])` to `r max(continuous_movies$metacritic_rating)*as.numeric(coef(fit_slr_metacritic)[2]) + as.numeric(coef(fit_slr_metacritic)[1])` despite my rating range going from `r min(continuous_movies$my_rating)` to `r max(continuous_movies$my_rating)`.

## MLR
```{r conditional_block5_2, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r mlr}
fit_mlr_rating = lm(my_rating~imdb_rating+metacritic_rating+tmdb_rating,data=continuous_movies) # create an MLR with just movie ratings from other sources
prettify(summary(fit_mlr_rating))
fit_mlr_count = lm(my_rating~imdb_count+imdb_top_1000_count+imdb_us_count+imdb_not_us_count,data=continuous_movies)
prettify(summary(fit_mlr_count)) # create an MLR with just movie rating counts
fit_mlr_full = lm(my_rating~.-name,data=continuous_movies) # create an MLR with all linear terms
prettify(summary(fit_mlr_full))
```
```{r mlr_plot, echo=FALSE}
plot(continuous_movies$my_rating, fit_mlr_rating$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="MLR My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_mlr_count$fitted.values,col="aquamarine3")
points(continuous_movies$my_rating,fit_mlr_full$fitted.values,col="firebrick4")
legend(x = "topleft", title="Models", bg="transparent",
       legend=c("All Ratings", 'All Counts',"All"),
       fill = c("orchid","aquamarine3",'firebrick4'))
abline(0,1)
```
The full MLR is an improvement but all ratings and all counts models are not particularly effective. Looking at the ratings MLR, the only significant term is the IMDB rating and the adjusted r squared only increases `r summary(fit_mlr_rating)$adj.r.squared-summary(fit_slr_imdb)$adj.r.squared` between the 2 models. Although many of the counts are significant, the overall model r squared is quite low at `r summary(fit_mlr_count)$adj.r.squared`. This occurs because of the uncapped counts that I mentioned in data analysis.

## Transformed and Polynomial MLRs
```{r conditional_block5_3, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r transform}
fit_full = lm(my_rating~.-name+log(imdb_count)+log(tmdb_count)+log(imdb_us_count)+log(imdb_not_us_count), data=continuous_movies) # start by creating a full and add some log terms for values not bounded to a specific range
prettify(summary(fit_full))
fit_log_count = lm(my_rating~log(imdb_count)+imdb_rating,data=continuous_movies) # simple model with my_rating to imdb_rating and log(imdb_count)
prettify(summary(fit_log_count))
```
```{r transform_plot, echo=FALSE}
plot(continuous_movies$my_rating, fit_full$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="Transformations My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_log_count$fitted.values,col="aquamarine3")
legend(x = "topleft", title="Models", bg="transparent",
       legend=c("Full", "IMDB+log(imdb_count)"),
       fill = c("orchid","aquamarine3"))
abline(0,1)
```

The full fit is able to get a high r squared of `r summary(fit_full)$adj.r.squared` because it includes many different variables and can be granular about matching them. However, many of the coefficients it chooses do not make sense for interpretation such as negative betas for imdb_rating and various counts. Moreover, the simpler model with just log(imdb_count) and imdb_rating is much more interpretable as both models have positive betas as expected.

## Polynomial and Interaction
```{r conditional_block5_4, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r polynomial_interaction}
fit_poly_imdb = lm(my_rating~poly(imdb_rating, degree=5),data=continuous_movies) # fitting a cubic model with imdb_rating
prettify(summary(fit_poly_imdb))
fit_polym = lm(my_rating ~ polym(imdb_rating, imdb_count, award_count, degree=5, raw=TRUE),data=continuous_movies) # fitting with a very big polynomial
s_polym = summary(fit_polym)
s_polym$adj.r.squared
fit_interaction = lm(my_rating~imdb_rating*is_animation+imdb_rating*is_family + imdb_rating*is_adventure + imdb_rating*is_action+imdb_rating*is_drama+imdb_rating*is_comedy+imdb_rating*is_thriller+imdb_rating*is_scifi+revenue*is_animation+revenue*is_action+revenue*is_drama+revenue*is_comedy+revenue*is_thriller+revenue*is_scifi+log(imdb_count)+imdb_rating*is_rated_r+imdb_rating*is_rated_nr+imdb_rating*is_rated_pg13+imdb_rating*is_rated_nr+imdb_rating*is_rated_g,data=continuous_movies)
prettify(summary(fit_interaction))
```
```{r polynomial_interaction_plot, echo=FALSE}
plot(continuous_movies$my_rating, fit_poly_imdb$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_polym$fitted.values,col="aquamarine3")
points(continuous_movies$my_rating,fit_interaction$fitted.values,col="firebrick4")
legend(x = "topleft", title="Models", bg="transparent",
       legend=c("IMDB^5", "Polym",'Interaction'),
       fill = c("orchid","aquamarine3",'firebrick4'))
abline(0,1)
```

The fifth degree polynomial based on IMDB rating is not very effective. In fact, it is not more significant than a simple linear model with IMDB rating.

```{r anova_poly_imdb}
anova(fit_poly_imdb, fit_slr_imdb)
```
The multiple polynomial has a very solid r squared: `r s_polym$adj.r.squared`. However, this comes at the price of interpretability. Trying to consider what a 1 unit difference award_count does when there are terms like the following is extremely difficult.
$$
imdbrating^2+imdbcount+awardcount^2
$$
Finally, the interaction terms are not particularly useful as only 2 of them are significant: is_rated_r, and is_drama. Besides those, the only 2 things the model finds significant are imdb_rating, and log(imdb_count) which are present in fit_log_count.

```{r anova_log_count}
anova(fit_log_count, fit_interaction)
```
This results in the two models not being significantly different based on anova.

## Ridge and Lasso {.tabset}
```{r conditional_block5_5, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r load_glmnet, include=FALSE}
library(glmnet)
set.seed(1)
```
Create data matrix to be used for both ridge and lasso.
```{r glmnet_matrix}
X = model.matrix(~ -1 + sqrt(imdb_count) + imdb_rating + sqrt(award_count), data = continuous_movies) # model to use for ridge and lasso fits
y = continuous_movies$my_rating

fit_lm = lm(my_rating ~ sqrt(imdb_count)+ imdb_rating + sqrt(award_count), data = continuous_movies) # non-ridge and lasso to compare to
```
### Ridge
```{r ridge}
fit_ridge = glmnet(X,y,alpha=0) # ridge fit
fit.cv.ridge = cv.glmnet(X,y,alpha=0)
# plot(fit.cv.ridge)
```

### Lasso
```{r lasso}
fit_lasso = glmnet(X,y,alpha=1) # lasso fit
fit.cv.lasso = cv.glmnet(X,y,alpha=1)
# plot(fit.cv.lasso)
```

### Comparison
```{r compare_glmnet, echo=FALSE}
beta_hat_mlr = coef(fit_lm)
beta_hat_ridge = coef(fit.cv.ridge, s = "lambda.1se")
beta_hat_lasso = coef(fit.cv.lasso, s = "lambda.1se")
cbind(beta_hat_mlr, beta_hat_ridge, beta_hat_lasso)

plot(continuous_movies$my_rating,predict(glmnet(X,y,alpha=0),as.matrix(X),s=fit.cv.ridge$lambda.1se),xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="GLMNET My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,predict(glmnet(X,y,alpha=1),as.matrix(X),s=fit.cv.lasso$lambda.1se),col="aquamarine3")
points(continuous_movies$my_rating,fit_lm$fitted.values,col="firebrick4")
legend(x = "topleft", title="Models", 
       legend=c("Ridge", "Lasso", "MLR"), 
       fill = c("orchid","aquamarine3",'firebrick4'))
abline(0,1)
```

### Lasso Full
```{r lasso_full}
X2 = model.matrix(~.-name-my_rating+log(imdb_count)+log(tmdb_count)+log(imdb_us_count)+log(imdb_not_us_count), data=continuous_movies)
fit_lasso_full = glmnet(X2,y,alpha=1) # lasso fit
fit.cv.lasso_full = cv.glmnet(X2,y,alpha=1)
# plot(fit.cv.lasso_full)
```

### Comparison Full
```{r compare_glmnet_full}
beta_hat_mlr_full = coef(fit_full)
beta_hat_lasso_full = coef(fit.cv.lasso_full, s = "lambda.1se")
cbind(beta_hat_mlr_full, beta_hat_lasso_full)
```
```{r compare_glmnet_full_plot, echo=FALSE}
plot(continuous_movies$my_rating,predict(glmnet(X2,y,alpha=0),as.matrix(X2),s=fit.cv.lasso_full$lambda.1se),xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="Full GLMNET My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_mlr_full$fitted.values,col="aquamarine3")
legend(x = "topleft", title="Models", 
       legend=c("Lasso Full", "MLR Full"), 
       fill = c("orchid","aquamarine3"))
abline(0,1)
```

Adjusted R Squared at 1 standard deviation for ridge and lasso:

* ridge: `r fit_ridge$dev.ratio[length(fit_ridge$dev.ratio)]`
* lasso: `r fit_lasso$dev.ratio[length(fit_lasso$dev.ratio)]`
* mlr: `r summary(fit_lm)$adj.r.squared`
* full lasso: `r fit_lasso_full$dev.ratio[length(fit_lasso_full$dev.ratio)]`
* full mlr: `r summary(fit_full)$adj.r.squared`

Lasso and ridge result in a slight improvement over the MLR since they take advantage of the bias variance tradeoff. Looking at the beta values, the different models change the coefficients a lot despite getting similar results. MLR values IMDB count and IMDB rating much more than ridge or lasso. Lasso actually removes sqrt(award_count) to not much of a detriment.

When comparing the full models, fit_lasso is highly predictive. Out of the 65 initial variables, it selects 12 variables. Each variables lasso selects has positive coefficients, so the interpretation of the model makes substantially more sense than the full model. However, the lasso model does include multiple versions of similar terms, indicating potential overfitting. For example, it includes imdb_rating, imdb_top_1000_rating, imdb_us_rating, imdb_not_us_rating, and imdb_rating_percentile â€” all of which are very similar. It repeats this flaw by including imdb_count, imdb_top_1000_count, and log(imdb_count). The only dummy variable lasso includes is is_john_williams.


## Steps with AIC and BIC {.tabset}
```{r conditional_block5_6, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r leaps}
library(leaps) # procedure from lab
fit_null = lm(my_rating~1, data=continuous_movies) # create a null fit to just an intercept
```
```{r anova}
anova(fit_null,fit_full,test='F') # make sure that the full fit is more significant than the null fit
```
Because the p-value for the full model is significant in comparison to the null model, it makes sense to continue with AIC and BIC to find a significant model. The use of AIC and BIC is to penalize adding more parameters because any parameter improves the fit. 
```{r aic_bic, results='hide'}
fit_aic = step(fit_null,list(upper=fit_full),direction='forward') # run AIC
n = nrow(continuous_movies)
fit_bic = step(fit_null,list(upper=fit_full),direction='forward',k=log(n)) # run BIC
```
```{r compare_aic_bic}
prettify(summary(fit_aic))
prettify(summary(fit_bic))
```
```{r compare_aic_bic_plot, echo=FALSE}
plot(continuous_movies$my_rating, fit_aic$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_bic$fitted.values,col="aquamarine3")
legend(x = "topleft", title="Models", 
       legend=c("AIC", "BIC"), 
       fill = c("orchid","aquamarine3"))
abline(0,1)
```

AIC and BIC had very different results. The AIC resulted in my highest adjusted R^2 of any model (`r summary(fit_aic)$adj.r.squared`). The final AIC selected `r length(fit_aic$coefficients)` coefficients. This is very different than the BIC which selected `r length(fit_bic$coefficients)`. Only 3 variables in the AIC have negative betas, is_jack_nicholoson, is_adventure, and imdb_rating. This is unique to this model and the full model and is possible because lots of people have highly positive coefficients and log(imdb_count) is also highly positive. Moreover, imdb_rating does not have a signifcant p-value in this model. The BIC chooses a much sparser with just imdb_rating, log(imdb_count), and is_john_williams. Based on these selctions, BIC avoids the flaw of lasso including multiple highly correlated variables. Both full lasso and BIC include is_john_williams as the only dummy variable. John Williams is not only an excellent composer but links many of my favorite movies such as Indiana Jones and Star Wars while only appearing in 2 movies I rated below a 60: Close Encounters of the Third Kind and The Lost World: Jurassic Park. Even with such different models, both the AIC and BIC had similar adjusted r squared values and their adjusted r squared values were generally in line with other models.

## General Additive Models {.tabset}
```{r conditional_block5_7, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

```{r load_mgcv, include=FALSE}
library(mgcv)
```
### Large GAM
```{r large_gam}
fit_gam1 = gam(my_rating~s(imdb_rating)+s(metacritic_rating)+s(tmdb_rating)+s(imdb_count)+s(award_count)+s(runtime)+s(imdb_arithmetic_mean),data=continuous_movies)
summary(fit_gam1)
```

### GAM with BIC Variables
```{r gam_bic}
fit_gam2 = gam(my_rating~s(imdb_rating)+s(imdb_count)+is_john_williams+log(imdb_count)*is_john_williams,data=continuous_movies)
summary(fit_gam2)
```

### Comparison
```{r, echo=FALSE}
plot(continuous_movies$my_rating, fit_gam1$fitted.values,xlim=c(0,100),ylim=c(0,100),xlab="My Rating",ylab="Fitted Values",main="My Rating vs Fitted Values",col="orchid")
points(continuous_movies$my_rating,fit_gam2$fitted.values,col="aquamarine3")
legend(x = "topleft", title="Models", bg="transparent",
       legend=c("GAM 1", "GAM 2"), 
       fill = c("orchid","aquamarine3"))
abline(0,1)
```

```{r gam_fits, include=FALSE}
plot(fit_gam1)
plot(fit_gam2)
```
GAM fit plots withheld for spacing reasons. Based on the GAM fit plots, IMDB rating and metacritic rating are linear. TMDB rating is linear until the rating reaches about 6 before increase in slope between 6.5 and 7.5 before flattening. This means that the impact of an increase in TMDB rating from 7.5 to 7.6 is expected to have a larger impact on my rating than an increase from 6.4 to 6.5. IMDB count has a very steep slope until it reaches around 500,000 before flattening out. This impact is fixed by using a log transformation Finally, runtime actually flips. When runtime is under an hour, an increase in runtime leads to an expected increase in my rating. However, as runtime passes 150 minutes, a higher runtime means an expected decrease in my rating. IMDB arithmetic rating is a new addition to this model and actually has a negative beta model. This exemplifies the slight difference in the way the public IMDB rating is calculated vs the arithmetic mean. The public IMDB rating is calculated using a secret formula to prevent review bombing and is actually a weighted average. This reveals that using the weighted mean is more powerful than the arithmetic mean and that the weighted average used by IMDB is useful. 

```{r budget_0, include=FALSE}
budget_not0 = continuous_movies%>%filter(budget!=0)
budget_0 = continuous_movies%>%filter(budget==0)
budget_not0 = mean(budget_not0$imdb_count)
budget_0 = mean(budget_0$imdb_count)
```
For budget, there is a quick slope upward at the beginning revealing that a percentage increase in budget is more important that a dollar amount increase. However, this should be taken with a grain of salt as there are flaws to using budget as a prediction metric. Firstly, movies have been made at all different times and budgets are not normalized for inflation. This harms the predictive power of using budget. Moreover, some movies do not have public budget information which is related to their popularity. The mean IMDB count for a movie with a budget that is not 0 is `r budget_not0` while for movies with a budget that is 0 the mean count is `r budget_0`, `r budget_not0/budget_0` times smaller.

# Summary and discussion 
```{r conditional_block6, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### What are the main conclusions of your analysis? What are the main limitations? What might be investigated in future research?

Ultimately, the model that I ended up liking the most was the BIC. This model includes imdb_rating, log(imdb_count), and is_john_williams. The model has an adjusted r squared of `r summary(fit_bic)$adj.r.squared`. This is very similar to the GAM version of the model which includesa smoothed version version of imdb_rating and imdb_count, a standard dummy variable of is_john_williams and an interaction term between is_john_williams and log(imdb_count). This resulted in an adjusted r squared of `r summary(fit_gam2)$r.sq`. Since the simple MLR found by BIC is much simpler and has a very similar r squared, it is the better choice for interpretability. 

```{r coef, include=FALSE}
coefs = coef(summary(fit_bic))
```

Interpretation. A movie with an IMDB rating of 0, that has been seen by 1 person, and does not have John Williams would be expected to have a rating of `r coefs[1]`. For each 1 unit increase in IMDB rating, holding all else equal, my expected rating increases by `r coefs[1]`. For each 1 unit increase in log(IMDB count), holding all else equal, my expected rating increases by `r coefs[2]`. If John Williams is credited in the movie, holding all else equal, my expected rating increases by `r coefs[3]`.

My largest conclusion in this project is that predicting my ratings if very difficult and that adjusted r squared of around 0.47 are the best I am going to do. I reached this conclusion since I fit many different models and ended up with results consistently similar despite highly different betas. Even with these varied betas, models consistently overpredicted low values and undepredicted high values. This makes sense considering each of the things that I am predicting based on are aggregate metrics. When trying to turn these aggregate metrics back to an individual prediction, the model hedges and predicts values generally closer to the center. This allows the model to miss by less when it is not particularly close.

```{r top5_bottom5, include=FALSE}
top5=continuous_movies[topn(fit_bic$residuals, 5L, decreasing = TRUE, index=TRUE),]$name
top5_values = as.numeric(topn(fit_bic$residuals, 5L, decreasing = TRUE,index=FALSE))
bottom5=continuous_movies[topn(fit_bic$residuals, 5L, decreasing = FALSE, index=TRUE),]$name
bottom5_values = as.numeric(topn(fit_bic$residuals, 5L, decreasing = FALSE,index=FALSE))
```
Fit BIC Outliers

* `r top5[1]`: `r top5_values[1]`
* `r top5[2]`: `r top5_values[2]`
* `r top5[3]`: `r top5_values[3]`
* `r top5[4]`: `r top5_values[4]`
* `r top5[5]`: `r top5_values[5]`
* `r bottom5[1]`: `r bottom5_values[1]`
* `r bottom5[2]`: `r bottom5_values[2]`
* `r bottom5[3]`: `r bottom5_values[3]`
* `r bottom5[4]`: `r bottom5_values[4]`
* `r bottom5[5]`: `r bottom5_values[5]`


```{r bic_plot, echo=FALSE}
residual_threshold = 33
high_residuals = continuous_movies %>% mutate(
  fitted = fit_bic$fitted.values,
  label = ifelse(abs(fit_bic$residuals)>residual_threshold|fitted>85|fitted<15,name,'')
)
ggplot(high_residuals) + xlim(c(0,100)) + ylim(c(0,100)) + geom_point(data=high_residuals, aes(x = my_rating, y = fit_bic$fitted.values), color=ifelse(high_residuals$label != '',"firebrick4","aquamarine3")) + geom_abline(aes(intercept=0,slope=1)) + labs(x="My Rating",y="Fitted Values", title="BIC My Rating vs Fitted Values") + geom_text_repel(data=high_residuals, aes(x=my_rating, y=fitted, label=label),max.overlaps = Inf)
```

## Diagnostics
```{r bic_diagnostics, echo=FALSE}
plot(fit_bic)
```
Out of the fit diagnostics, residuals vs fitted and residuals vs leverage both look good. The normal QQ plot tails off slightly below for higher theoretical quantiles but stays on the line for most of the points, This tailing off is because my ratings are bounded between 0 and 100 while a normal distribution is not. This result is not worrying and errors can be treated as Gaussian. The scale location plot contains a slightly downward slope at higher fitted values. This is okay because the data is much sparser at those values so the final model assumptions for MLR still hold.

## Predictions

The movies being predicted are the most reviewed movies on IMDB that I have not seen. In order they are Inglorious Basterds, The Silence of the Lambs, Saving Private Ryan, The Departed, Shutter Island, The Green Mile, Titanic, American Beauty, American History X, Braveheart, and The Hottie & the Nottie.

```{r predictions, include=TRUE}
most_reviewed = data.frame(imdb_rating=c(8.3,8.6,8.6,8.5,8.2,8.6,7.9,8.4,8.5,8.4,1.9),imdb_count=c(1389883,1381370,1342619,1282577,1253738,1253525,1130852,1130000,1094160,1014965,38184),is_john_williams=c(0,0,1,0,0,0,0,0,0,0,0))
predictions = predict(fit_bic, most_reviewed, interval="prediction")
predictions
```

These predictions are mostly reasonable but they do fall within very large ranges. On the high end, the predictions get above 100 and on the low end they get below 0. I feel confident that I would rate nearly all of these movies within the given range; however, the ranges encompass over half of the rating space. These ranges means the model must hedge because it cannot continuously predict values of 90 for movies with ranges between 63 and 117 because the range on the upper end is impossible and the model will attempt to avoid it.

Overall, predicting my movie ratings is very difficult to make highly accurate, but it is certainly possible to do much better than random guessing, and with careful variable, it is possible to get a relatively accurate model with high interpretability.

# References 
```{r conditional_block7, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### What are the sources for the data and any additional statistical resources that you used to support your analysis?

Data sources:

* [TMDB API](https://www.themoviedb.org/documentation/api)
* [IMDB Website](https://www.imdb.com/)
* [Personal Movie Website](https://www.tradethisandthat.com/movies/)
```{py django, results=FALSE}
from django.core.management.base import BaseCommand
from movies.models import *
import csv, os


class Command(BaseCommand):
    help = 'create full database from csv'

    def handle(self, *args, **options):
        FOLDER = os.path.dirname(os.path.abspath(__file__))
        with open(os.path.join(FOLDER, './csv/movie.csv'), 'w',
                  encoding='UTF8', newline='') as csvfile:
            filewriter = csv.writer(csvfile)
            filewriter.writerow(
                ['uuid', 'franchise_id', 'mpaa_id', 'imdb_rating', 'metacritic_rating', 'my_rating', 'tmdb_id',
                 'imdb_id', 'name', 'tmdb_rating', 'tmdb_count', 'poster', 'runtime', 'release_date', 'recent_watch',
                 'viewing_count', 'release_day', 'release_month', 'release_year', 'revenue', 'budget',
                 'distance_from_rating_average', 'my_rating_percentile', 'imdb_rating_percentile',
                 'tmdb_rating_percentile', 'metacritic_rating_percentile', 'genre_ids', 'award_ids', 'award_count',
                 'production_company_ids', 'franchise_name', 'mpaa_name', 'genres_names', 'genre_numbers',
                 'award_names', 'production_company_names', 'imdb_count', 'imdb_arithmetic_mean', 'imdb_median',
                 'imdb_top_1000_rating', 'imdb_top_1000_count', 'imdb_us_rating', 'imdb_us_count', 'imdb_not_us_rating',
                 'imdb_not_us_count']
            )
            genres = WatchInfo.objects.filter(watch_info_type='Genre')
            genre_dict = {genre: i for i, genre in enumerate(genres)}
            for movie in Movie.objects.all():
                filewriter.writerow(
                    [movie.uuid, (movie.franchise_id if movie.franchise is not None else ''),
                     (movie.mpaa_rating_id if movie.mpaa_rating is not None else ''), movie.imdb_rating,
                     movie.metacritic_rating, movie.my_rating_field, movie.tmdb_id, movie.imdb_id, movie.name,
                     movie.tmdb_rating, movie.tmdb_count, movie.poster, movie.runtime, movie.release_date,
                     movie.recent_watch, movie.viewing_count, movie.release_day.name, movie.release_month.name,
                     movie.release_year.name, movie.revenue, movie.budget, movie.distance_from_rating_average,
                     movie.rating_percentile, movie.imdb_rating_percentile, movie.tmdb_rating_percentile,
                     movie.metacritic_rating_percentile,
                     [x.pk for x in movie.genres.all()], [x.pk for x in movie.awards.all()], movie.award_count,
                     [x.pk for x in movie.production_companies.all()],
                     (movie.franchise.name if movie.franchise is not None else ''),
                     (movie.mpaa_rating.name if movie.mpaa_rating is not None else ''),
                     [x.name for x in movie.genres.all()], [genre_dict[x] for x in movie.genres.all()],
                     [x.name for x in movie.awards.all()],
                     [x.name for x in movie.production_companies.all()], movie.imdb_count, movie.imdb_arithmetic_mean,
                     movie.imdb_median, movie.imdb_top_1000_rating, movie.imdb_top_1000_count, movie.imdb_us_rating,
                     movie.imdb_us_count, movie.imdb_not_us_rating, movie.imdb_not_us_count
                     ]
                )
        with open(os.path.join(FOLDER, './csv/place.csv'), 'w',
                  encoding='UTF8', newline='') as csvfile:
            filewriter = csv.writer(csvfile)
            filewriter.writerow(['uuid', 'city', 'state', 'country'])
            for place in Place.objects.all():
                filewriter.writerow([place.uuid, place.city, place.state, place.country])
        with open(os.path.join(FOLDER, './csv/person.csv'), 'w',
                  encoding='UTF8', newline='') as csvfile:
            filewriter = csv.writer(csvfile)
            filewriter.writerow(
                ['uuid', 'tmdb_id', 'name', 'main_role', 'birth_place_id', 'image', 'number_of_movies', 'total_rating',
                 'credit_weighted_score']
            )
            for person in Person.objects.all():
                filewriter.writerow([person.uuid, person.tmdb_id, person.name, person.main_role,
                                     (person.birth_place_id if person.birth_place is not None else ''), person.image,
                                     person.number_of_movies_field, person.total_rating_field,
                                     person.credit_order_weighted_score_field])
        with open(os.path.join(FOLDER, './csv/watch_info.csv'), 'w',
                  encoding='UTF8', newline='') as csvfile:
            filewriter = csv.writer(csvfile)
            filewriter.writerow(
                ['uuid', 'name', 'type', 'movie_count', 'category_average', ]
            )
            for watch_info in WatchInfo.objects.all():
                filewriter.writerow(
                    [watch_info.uuid, watch_info.name, watch_info.watch_info_type, watch_info.movie_count,
                     watch_info.category_average])
            with open(os.path.join(FOLDER, './csv/viewing.csv'), 'w',
                      encoding='UTF8', newline='') as csvfile:
                filewriter = csv.writer(csvfile)
                filewriter.writerow(
                    ['uuid', 'movie_id', 'watch_date', 'watch_location_id', 'watch_device_id', 'watch_platform_id',
                     'viewing_people_ids', 'review', 'my_rating']
                )
                for viewing in Viewing.objects.all():
                    filewriter.writerow([viewing.uuid, viewing.movie_id, viewing.watch_date,
                                         (viewing.watch_location_id if viewing.watch_location is not None else ''),
                                         (viewing.watch_device_id if viewing.watch_device is not None else ''),
                                         (viewing.watch_platform_id if viewing.watch_platform is not None else ''),
                                         [x.pk for x in viewing.people_with.all()], viewing.review, viewing.my_rating])
            with open(os.path.join(FOLDER, './csv/credit.csv'), 'w',
                      encoding='UTF8', newline='') as csvfile:
                filewriter = csv.writer(csvfile)
                filewriter.writerow(
                    ['uuid', 'person_id', 'movie_id', 'department', 'character_job', 'order', 'order_score',
                     'order_weighted_score']
                )
                for credit in Credit.objects.all():
                    filewriter.writerow(
                        [credit.uuid, credit.person_id, credit.movie_id, credit.department, credit.character_job,
                         credit.order, credit.order_score, credit.credit_order_weighted_score])
```
# Code and data 
```{r conditional_block8, echo=FALSE, results='asis', eval=SHOW_BACK_TO_TOP}
cat('<a href="#top">Back to top</a>')
```

#### Include the code and data to reproduce your analysis. The code should include clear comments and should run correctly without errors.
Code and data included throughout.

Datasets available on [Github](https://github.com/AidanG1/stat410) and on the hosted version of the html: [movie.csv](https://stat.aidang.me/movie.csv), [credit.csv](https://stat.aidang.me/credit.csv), [continuous_movies](https://stat.aidang.me/continuous_movies.csv), and [pdf form](https://stat.aidang.me/finalProject.pdf).